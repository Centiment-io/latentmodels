{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First tutorial from http://radimrehurek.com/gensim/"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      ">>> from gensim import corpora, models, similarities\n",
      ">>>\n",
      ">>> corpus = [[(0, 1.0), (1, 1.0), (2, 1.0)],\n",
      ">>>           [(2, 1.0), (3, 1.0), (4, 1.0), (5, 1.0), (6, 1.0), (8, 1.0)],\n",
      ">>>           [(1, 1.0), (3, 1.0), (4, 1.0), (7, 1.0)],\n",
      ">>>           [(0, 1.0), (4, 2.0), (7, 1.0)],\n",
      ">>>           [(3, 1.0), (5, 1.0), (6, 1.0)],\n",
      ">>>           [(9, 1.0)],\n",
      ">>>           [(9, 1.0), (10, 1.0)],\n",
      ">>>           [(9, 1.0), (10, 1.0), (11, 1.0)],\n",
      ">>>           [(8, 1.0), (10, 1.0), (11, 1.0)]]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      ">>> tfidf = models.TfidfModel(corpus)\n",
      ">>> vec = [(0, 1), (4, 1)]\n",
      ">>> print(tfidf[vec])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[(0, 0.8075244024440723), (4, 0.5898341626740045)]\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      ">>> index = similarities.SparseMatrixSimilarity(tfidf[corpus], num_features=12)\n",
      ">>> sims = index[tfidf[vec]]\n",
      ">>> print(list(enumerate(sims)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[(0, 0.4662244), (1, 0.19139354), (2, 0.24600551), (3, 0.82094586), (4, 0.0), (5, 0.0), (6, 0.0), (7, 0.0), (8, 0.0)]\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "LDA Tutorial:"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import gensim\n",
      "\n",
      "corpus = gensim.mode\n",
      "\n",
      "model = gensim.models.ldamodel.LdaModel(bow_corpus, id2word=dictionary, num_topics=100)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'bow_corpus' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-21-c962445d726b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mldamodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLdaModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbow_corpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid2word\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_topics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;31mNameError\u001b[0m: name 'bow_corpus' is not defined"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\" Example using GenSim's LDA and sklearn. \"\"\"\n",
      " \n",
      "import numpy as np\n",
      " \n",
      "from gensim import matutils\n",
      "from gensim.models.ldamodel import LdaModel\n",
      "from sklearn import linear_model\n",
      "from sklearn.datasets import fetch_20newsgroups\n",
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      " \n",
      " \n",
      "def print_features(clf, vocab, n=10):\n",
      "    \"\"\" Print sorted list of non-zero features/weights. \"\"\"\n",
      "    coef = clf.coef_[0]\n",
      "    print 'positive features: %s' % (' '.join(['%s/%.2f' % (vocab[j], coef[j]) for j in np.argsort(coef)[::-1][:n] if coef[j] > 0]))\n",
      "    print 'negative features: %s' % (' '.join(['%s/%.2f' % (vocab[j], coef[j]) for j in np.argsort(coef)[:n] if coef[j] < 0]))\n",
      " \n",
      " \n",
      "def fit_classifier(X, y, C=0.1):\n",
      "    \"\"\" Fit L1 Logistic Regression classifier. \"\"\"\n",
      "    # Smaller C means fewer features selected.\n",
      "    clf = linear_model.LogisticRegression(penalty='l1', C=C)\n",
      "    clf.fit(X, y)\n",
      "    return clf\n",
      " \n",
      " \n",
      "def fit_lda(X, vocab, num_topics=5, passes=20):\n",
      "    \"\"\" Fit LDA from a scipy CSR matrix (X). \"\"\"\n",
      "    print 'fitting lda...'\n",
      "    return LdaModel(matutils.Sparse2Corpus(X), num_topics=num_topics,\n",
      "                    passes=passes,\n",
      "                    id2word=dict([(i, s) for i, s in enumerate(vocab)]))\n",
      " \n",
      " \n",
      "def print_topics(lda, vocab, n=10):\n",
      "    \"\"\" Print the top words for each topic. \"\"\"\n",
      "    topics = lda.show_topics(topics=-1, topn=n, formatted=False)\n",
      "    for ti, topic in enumerate(topics):\n",
      "        print 'topic %d: %s' % (ti, ' '.join('%s/%.2f' % (t[1], t[0]) for t in topic))\n",
      " \n",
      " \n",
      "if (__name__ == '__main__'):\n",
      "    # Load data.\n",
      "    rand = np.random.mtrand.RandomState(8675309)\n",
      "    cats = ['rec.sport.baseball', 'sci.crypt']\n",
      "    data = fetch_20newsgroups(subset='train',\n",
      "                              categories=cats,\n",
      "                              shuffle=True,\n",
      "                              random_state=rand)\n",
      "    vec = CountVectorizer(min_df=10, stop_words='english')\n",
      "    X = vec.fit_transform(data.data)\n",
      "    vocab = vec.get_feature_names()\n",
      " \n",
      "    # Fit classifier.\n",
      "    #clf = fit_classifier(X, data.target)\n",
      "    #print_features(clf, vocab)\n",
      " \n",
      "    # Fit LDA.\n",
      "    lda = fit_lda(X, vocab)\n",
      "    print_topics(lda, vocab)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "________________________________________________________________________________\n",
        "Cache loading failed\n",
        "________________________________________________________________________________\n",
        "Error -5 while decompressing data: incomplete or truncated stream\n",
        "fitting lda..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "topic 0: generate/0.02 biochem/0.02 cf/0.01 favorite/0.01 authentication/0.01 america/0.01 11/0.01 flame/0.01 d1/0.01 end/0.01"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "topic 1: er/0.05 general/0.04 162/0.04 asbestos/0.03 anderson/0.03 9760/0.03 corresponding/0.03 explain/0.02 brother/0.02 contains/0.02\n",
        "topic 2: contains/0.11 correct/0.09 cf/0.07 awful/0.04 digitized/0.03 fenway/0.03 content/0.03 famous/0.03 everybody/0.03 account/0.02\n",
        "topic 3: cf/0.01 301/0.01 come/0.01 ee/0.01 aa/0.01 128/0.01 cs/0.00 engineering/0.00 classified/0.00 43/0.00\n",
        "topic 4: fri/0.02 d3/0.02 close/0.01 gold/0.01 creation/0.01 att/0.01 funds/0.01 fresh/0.01 convert/0.01 354/0.01\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "From Radim Rehurek:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      ">>> from gensim import corpora, models, similarities\n",
      ">>>\n",
      ">>> documents = [\"Human machine interface for lab abc computer applications\",\n",
      ">>>              \"A survey of user opinion of computer system response time\",\n",
      ">>>              \"The EPS user interface management system\",\n",
      ">>>              \"System and human system engineering testing of EPS\",\n",
      ">>>              \"Relation of user perceived response time to error measurement\",\n",
      ">>>              \"The generation of random binary unordered trees\",\n",
      ">>>              \"The intersection graph of paths in trees\",\n",
      ">>>              \"Graph minors IV Widths of trees and well quasi ordering\",\n",
      ">>>              \"Graph minors A survey\"]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print sum( texts )\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['human', 'machine', 'interface', 'lab', 'abc', 'computer', 'applications', 'survey', 'user', 'opinion', 'computer', 'system', 'response', 'time', 'eps', 'user', 'interface', 'management', 'system', 'system', 'human', 'system', 'engineering', 'testing', 'eps', 'relation', 'user', 'perceived', 'response', 'time', 'error', 'measurement', 'generation', 'random', 'binary', 'unordered', 'trees', 'intersection', 'graph', 'paths', 'trees', 'graph', 'minors', 'iv', 'widths', 'trees', 'well', 'quasi', 'ordering', 'graph', 'minors', 'survey']\n"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      ">>> # remove common words and tokenize\n",
      ">>> stoplist = set('for a of the and to in'.split())\n",
      ">>> texts = [[word for word in document.lower().split() if word not in stoplist]\n",
      ">>>          for document in documents]\n",
      ">>>\n",
      ">>> # remove words that appear only once\n",
      ">>> all_tokens = sum(texts )\n",
      ">>> tokens_once = set(word for word in set(all_tokens) if all_tokens.count(word) == 1)\n",
      ">>> texts = [[word for word in text if word not in tokens_once]\n",
      ">>>          for text in texts]\n",
      ">>>\n",
      ">>> print(texts)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[['human', 'interface', 'computer'], ['survey', 'user', 'computer', 'system', 'response', 'time'], ['eps', 'user', 'interface', 'system'], ['system', 'human', 'system', 'eps'], ['user', 'response', 'time'], ['trees'], ['graph', 'trees'], ['graph', 'minors', 'trees'], ['graph', 'minors', 'survey']]\n"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      ">>> dictionary = corpora.Dictionary(texts)\n",
      ">>> dictionary.save('/tmp/deerwester.dict') # store the dictionary, for future reference\n",
      ">>> print(dictionary)\n",
      ">>> print(dictionary.token2id)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Dictionary(12 unique tokens: [u'minors', u'graph', u'system', u'trees', u'eps']...)\n",
        "{u'minors': 11, u'graph': 10, u'system': 5, u'trees': 9, u'eps': 8, u'computer': 0, u'survey': 4, u'user': 7, u'human': 1, u'time': 6, u'interface': 2, u'response': 3}\n"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      ">>> new_doc = \"Human computer interaction\"\n",
      ">>> new_vec = dictionary.doc2bow(new_doc.lower().split())\n",
      ">>> print(new_vec) # the word \"interaction\" does not appear in the dictionary and is ignored\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[(0, 1), (1, 1)]\n"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      ">>> corpus = [dictionary.doc2bow(text) for text in texts]\n",
      ">>> corpora.MmCorpus.serialize('/tmp/deerwester.mm', corpus) # store to disk, for later use\n",
      ">>> print(corpus)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[(0, 1), (1, 1), (2, 1)], [(0, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1)], [(2, 1), (5, 1), (7, 1), (8, 1)], [(1, 1), (5, 2), (8, 1)], [(3, 1), (6, 1), (7, 1)], [(9, 1)], [(9, 1), (10, 1)], [(9, 1), (10, 1), (11, 1)], [(4, 1), (10, 1), (11, 1)]]\n"
       ]
      }
     ],
     "prompt_number": 37
    }
   ],
   "metadata": {}
  }
 ]
}